{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install transformers[sentencepiece] datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:34:11.412866Z","iopub.status.busy":"2022-05-02T01:34:11.412360Z","iopub.status.idle":"2022-05-02T01:39:56.153001Z","shell.execute_reply":"2022-05-02T01:39:56.152245Z","shell.execute_reply.started":"2022-05-02T01:34:11.412826Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/huggingface-course--codeparrot-ds-train to /root/.cache/huggingface/datasets/json/huggingface-course--codeparrot-ds-train-40ca73f561bc3fca/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6ecf04ab2dd497bb41ca0a02537551c","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7072be1ed4ea4d58bf748bb5a7adaabe","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/8.25G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5440fb66a154c6990c9de34473ca563","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/huggingface-course--codeparrot-ds-train-40ca73f561bc3fca/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"]}],"source":["from datasets import load_dataset, DatasetDict\n","\n","ds_train = load_dataset(\"huggingface-course/codeparrot-ds-train\", split=\"train\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:39:56.158782Z","iopub.status.busy":"2022-05-02T01:39:56.158095Z","iopub.status.idle":"2022-05-02T01:39:58.299022Z","shell.execute_reply":"2022-05-02T01:39:58.298318Z","shell.execute_reply.started":"2022-05-02T01:39:56.158741Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n","        num_rows: 16380\n","    })\n","    test: Dataset({\n","        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n","        num_rows: 1821\n","    })\n","})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets = ds_train.train_test_split(train_size=0.03, seed=20)\n","raw_datasets.pop(\"test\")\n","raw_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n","raw_datasets"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:39:58.300780Z","iopub.status.busy":"2022-05-02T01:39:58.300355Z","iopub.status.idle":"2022-05-02T01:39:58.306944Z","shell.execute_reply":"2022-05-02T01:39:58.306162Z","shell.execute_reply.started":"2022-05-02T01:39:58.300742Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n","        num_rows: 16380\n","    })\n","    validation: Dataset({\n","        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n","        num_rows: 1821\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets[\"validation\"] = raw_datasets.pop(\"test\")\n","raw_datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:39:58.309342Z","iopub.status.busy":"2022-05-02T01:39:58.309080Z","iopub.status.idle":"2022-05-02T01:39:58.323504Z","shell.execute_reply":"2022-05-02T01:39:58.322755Z","shell.execute_reply.started":"2022-05-02T01:39:58.309307Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["REPO_NAME: radical-experiments/AIMES-Experience\n","PATH: old/synapse_integration_testing/cleaned_data/experiments/plot.py\n","COPIES: 1\n","SIZE: 1132\n","CONTENT: import csv\n","import sys\n","import matplotlib.pyplot as plt\n","\n","\n","if sys.argv[1] == 'TTC':\n","    filename = 'TTC.csv'\n","elif sys.argv[1] == 'Tq':\n","    filename = 'Tq.csv'\n","elif sys.argv[1] == 'Tx':\n","    filename = 'Tx\n","LICENSE: mit\n"]}],"source":["for key in raw_datasets[\"train\"][0]:\n","    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:39:58.326937Z","iopub.status.busy":"2022-05-02T01:39:58.326755Z","iopub.status.idle":"2022-05-02T01:40:04.733922Z","shell.execute_reply":"2022-05-02T01:40:04.733106Z","shell.execute_reply.started":"2022-05-02T01:39:58.326915Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58101eadd3c54a8fb5a281709d0298e5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/265 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c97a2c68f7345f481eab54d9fa3cd99","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/771k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02ff15b8578c4f9688a574abd77c2f57","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/438k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14ce2c124a45459abc05064342291081","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.28M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae22d4a643bb4af5b11ec81514e36249","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Input IDs length: 27\n","Input chunk lengths: [128, 128, 128, 51, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 3]\n","Chunk mapping: [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]}],"source":["from transformers import AutoTokenizer\n","\n","context_length = 128\n","tokenizer = AutoTokenizer.from_pretrained(\"huggingface-course/code-search-net-tokenizer\")\n","\n","outputs = tokenizer(\n","    raw_datasets[\"train\"][:2][\"content\"],\n","    truncation=True,\n","    max_length=context_length,\n","    return_overflowing_tokens=True,\n","    return_length=True,\n",")\n","\n","print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n","print(f\"Input chunk lengths: {(outputs['length'])}\")\n","print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:40:04.736089Z","iopub.status.busy":"2022-05-02T01:40:04.735338Z","iopub.status.idle":"2022-05-02T01:43:37.161850Z","shell.execute_reply":"2022-05-02T01:43:37.161124Z","shell.execute_reply.started":"2022-05-02T01:40:04.736047Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c2c724f0f174be1ac3eb0512e4f6f7c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/17 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8708ca3240f74605a3a9fc88de5fd205","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids'],\n","        num_rows: 450339\n","    })\n","    validation: Dataset({\n","        features: ['input_ids'],\n","        num_rows: 49121\n","    })\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def tokenize(element):\n","    outputs = tokenizer(\n","        element[\"content\"],\n","        truncation=True,\n","        max_length=context_length,\n","        return_overflowing_tokens=True,\n","        return_length=True,\n","    )\n","    input_batch = []\n","    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n","        if length == context_length:\n","            input_batch.append(input_ids)\n","    return {\"input_ids\": input_batch}\n","\n","\n","tokenized_datasets = raw_datasets.map(\n","    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",")\n","tokenized_datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:43:37.163561Z","iopub.status.busy":"2022-05-02T01:43:37.163279Z","iopub.status.idle":"2022-05-02T01:43:38.038647Z","shell.execute_reply":"2022-05-02T01:43:38.037945Z","shell.execute_reply.started":"2022-05-02T01:43:37.163517Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30a66075cad447e5b09fbf02bb788bc6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n","\n","config = AutoConfig.from_pretrained(\n","    \"gpt2\",\n","    vocab_size=len(tokenizer),\n","    n_ctx=context_length,\n","    bos_token_id=tokenizer.bos_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:43:38.040323Z","iopub.status.busy":"2022-05-02T01:43:38.039928Z","iopub.status.idle":"2022-05-02T01:43:43.924151Z","shell.execute_reply":"2022-05-02T01:43:43.923373Z","shell.execute_reply.started":"2022-05-02T01:43:38.040286Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT-2 size: 124.2M parameters\n"]}],"source":["model = GPT2LMHeadModel(config)\n","model_size = sum(t.numel() for t in model.parameters())\n","print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:43:43.926040Z","iopub.status.busy":"2022-05-02T01:43:43.925622Z","iopub.status.idle":"2022-05-02T01:43:44.700119Z","shell.execute_reply":"2022-05-02T01:43:44.699107Z","shell.execute_reply.started":"2022-05-02T01:43:43.926002Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:43:44.723785Z","iopub.status.busy":"2022-05-02T01:43:44.721017Z","iopub.status.idle":"2022-05-02T01:43:49.697288Z","shell.execute_reply":"2022-05-02T01:43:49.696584Z","shell.execute_reply.started":"2022-05-02T01:43:44.723747Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using amp half precision backend\n"]}],"source":["from transformers import Trainer, TrainingArguments\n","\n","args = TrainingArguments(\n","    output_dir=\"gpt_code_gen\",\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=1000,\n","    logging_steps=500,\n","    gradient_accumulation_steps=8,\n","    num_train_epochs=2,\n","    weight_decay=0.1,\n","    warmup_steps=1_000,\n","    lr_scheduler_type=\"cosine\",\n","    learning_rate=5e-4,\n","    save_steps=500,\n","    save_total_limit=2,\n","    fp16=True,\n","    report_to=\"none\",\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=args,\n","    data_collator=data_collator,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T01:43:49.699180Z","iopub.status.busy":"2022-05-02T01:43:49.698976Z","iopub.status.idle":"2022-05-02T06:32:07.429286Z","shell.execute_reply":"2022-05-02T06:32:07.428264Z","shell.execute_reply.started":"2022-05-02T01:43:49.699154Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 450339\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 256\n","  Gradient Accumulation steps = 8\n","  Total optimization steps = 3518\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3518' max='3518' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3518/3518 4:48:12, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1000</td>\n","      <td>3.164000</td>\n","      <td>2.716587</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.210200</td>\n","      <td>2.150288</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.859400</td>\n","      <td>1.891417</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to gpt_code_gen/checkpoint-500\n","Configuration saved in gpt_code_gen/checkpoint-500/config.json\n","Model weights saved in gpt_code_gen/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-500/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 49121\n","  Batch size = 32\n","Saving model checkpoint to gpt_code_gen/checkpoint-1000\n","Configuration saved in gpt_code_gen/checkpoint-1000/config.json\n","Model weights saved in gpt_code_gen/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-1000/special_tokens_map.json\n","Saving model checkpoint to gpt_code_gen/checkpoint-1500\n","Configuration saved in gpt_code_gen/checkpoint-1500/config.json\n","Model weights saved in gpt_code_gen/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [gpt_code_gen/checkpoint-500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 49121\n","  Batch size = 32\n","Saving model checkpoint to gpt_code_gen/checkpoint-2000\n","Configuration saved in gpt_code_gen/checkpoint-2000/config.json\n","Model weights saved in gpt_code_gen/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [gpt_code_gen/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to gpt_code_gen/checkpoint-2500\n","Configuration saved in gpt_code_gen/checkpoint-2500/config.json\n","Model weights saved in gpt_code_gen/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [gpt_code_gen/checkpoint-1500] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 49121\n","  Batch size = 32\n","Saving model checkpoint to gpt_code_gen/checkpoint-3000\n","Configuration saved in gpt_code_gen/checkpoint-3000/config.json\n","Model weights saved in gpt_code_gen/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [gpt_code_gen/checkpoint-2000] due to args.save_total_limit\n","Saving model checkpoint to gpt_code_gen/checkpoint-3500\n","Configuration saved in gpt_code_gen/checkpoint-3500/config.json\n","Model weights saved in gpt_code_gen/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [gpt_code_gen/checkpoint-2500] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=3518, training_loss=2.7161174804531356, metrics={'train_runtime': 17297.6961, 'train_samples_per_second': 52.069, 'train_steps_per_second': 0.203, 'total_flos': 5.8832709894144e+16, 'train_loss': 2.7161174804531356, 'epoch': 2.0})"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T06:32:07.431372Z","iopub.status.busy":"2022-05-02T06:32:07.431014Z","iopub.status.idle":"2022-05-02T06:37:18.661301Z","shell.execute_reply":"2022-05-02T06:37:18.660507Z","shell.execute_reply.started":"2022-05-02T06:32:07.431333Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 49121\n","  Batch size = 32\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1536' max='1536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1536/1536 05:11]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 1.863879680633545,\n"," 'eval_runtime': 311.2194,\n"," 'eval_samples_per_second': 157.834,\n"," 'eval_steps_per_second': 4.935,\n"," 'epoch': 2.0}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T06:59:31.732993Z","iopub.status.busy":"2022-05-02T06:59:31.732315Z","iopub.status.idle":"2022-05-02T06:59:32.798507Z","shell.execute_reply":"2022-05-02T06:59:32.797717Z","shell.execute_reply.started":"2022-05-02T06:59:31.732952Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to gpt_code_gen\n","Configuration saved in gpt_code_gen/config.json\n","Model weights saved in gpt_code_gen/pytorch_model.bin\n","tokenizer config file saved in gpt_code_gen/tokenizer_config.json\n","Special tokens file saved in gpt_code_gen/special_tokens_map.json\n"]}],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from transformers import pipeline\n","\n","pipe = pipeline(\n","    \"text-generation\", model=\"gpt_code_gen\", device=0\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:02:54.883259Z","iopub.status.busy":"2022-05-02T07:02:54.882989Z","iopub.status.idle":"2022-05-02T07:02:55.014157Z","shell.execute_reply":"2022-05-02T07:02:55.013482Z","shell.execute_reply.started":"2022-05-02T07:02:54.883228Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["# create some data\n","x = np.random.randn(100)\n","y = np.random.randn(100)\n","\n","# create scatter plot with x, y\n","m = x + y + width # make sure it is the\n"]}],"source":["txt = \"\"\"\\\n","# create some data\n","x = np.random.randn(100)\n","y = np.random.randn(100)\n","\n","# create scatter plot with x, y\n","\"\"\"\n","print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
