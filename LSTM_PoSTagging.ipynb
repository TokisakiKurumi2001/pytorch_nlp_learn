{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_PoSTagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H6PCVgiivEsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00be4dd-e177-4951-f200-ec6978fc6c08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fec13eb0090>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = nn.LSTM(3, 3)\n",
        "inputs = [torch.randn(1, 3) for _ in range(5)]\n",
        "\n",
        "# initialize the hidden state\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
        "for i in inputs:\n",
        "  out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
        "\n",
        "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
        "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
        "out, hidden = lstm(inputs, hidden)\n",
        "print(out)\n",
        "print(hidden)"
      ],
      "metadata": {
        "id": "_LUlLzGzve80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ebc17f-5885-40cc-fca9-e830ac27bee1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
            "\n",
            "        [[-0.3521,  0.1026, -0.2971]],\n",
            "\n",
            "        [[-0.3191,  0.0781, -0.1957]],\n",
            "\n",
            "        [[-0.1634,  0.0941, -0.1637]],\n",
            "\n",
            "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n",
            "(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PoS tagging"
      ],
      "metadata": {
        "id": "JodJru2Y3AdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "def prepare_sequence(seq, to_idx):\n",
        "  idxs = [to_idx[w] for w in seq]\n",
        "  return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "training_data = [\n",
        "  (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "  (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
        "]\n",
        "vocab = set([el for data in training_data for el in data[0]])\n",
        "word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
        "tag_to_idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "idx_to_tag = {0: \"DET\", 1: \"NN\", 2: \"V\"}\n",
        "\n",
        "EMBED_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "print(word_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY7KLzvO3CYR",
        "outputId": "d3e332fb-a1d7-4133-a1ba-e9804f66419a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dog': 0, 'book': 1, 'the': 2, 'Everybody': 3, 'that': 4, 'ate': 5, 'apple': 6, 'read': 7, 'The': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "  def __init__(self, embed_dim, hidden_dim, vocab_size, tagset_size):\n",
        "    super(LSTMTagger, self).__init__()\n",
        "\n",
        "    self.word_embed = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim)\n",
        "\n",
        "    self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embeds = self.word_embed(sentence)\n",
        "    lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "    tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "    return tag_scores"
      ],
      "metadata": {
        "id": "x8eBm3mN5rs9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_beauti_res(sentence, tag_scores):\n",
        "  print(reduce(lambda x, y: f\"{x}\\t{y}\", sentence))\n",
        "  print(reduce(lambda x, y: f\"{x}\\t{y}\", [idx_to_tag[torch.argmax(scores).item()] for scores in tag_scores]))"
      ],
      "metadata": {
        "id": "oL0_YZtAODbz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMTagger(EMBED_DIM, HIDDEN_DIM, len(word_to_idx), len(tag_to_idx))\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
        "  tag_scores = model(inputs)\n",
        "  print(tag_scores)\n",
        "\n",
        "for epoch in range(300):\n",
        "  for sentence, tags in training_data:\n",
        "    model.zero_grad()\n",
        "\n",
        "    sentence_in = prepare_sequence(sentence, word_to_idx)\n",
        "    targets = prepare_sequence(tags, tag_to_idx)\n",
        "\n",
        "    tag_scores = model(sentence_in)\n",
        "\n",
        "    loss = loss_fn(tag_scores, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "  inputs = prepare_sequence(training_data[0][0], word_to_idx)\n",
        "  tag_scores = model(inputs)\n",
        "  print(tag_scores)\n",
        "  print_beauti_res(training_data[0][0], tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIhrm5KjM1QL",
        "outputId": "221e47c1-cc4c-4517-caeb-226e3b4ab498"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0564, -1.3608, -0.9267],\n",
            "        [-1.1500, -1.2674, -0.9118],\n",
            "        [-1.1602, -1.3702, -0.8381],\n",
            "        [-1.0840, -1.3456, -0.9129],\n",
            "        [-0.9573, -1.4038, -0.9931]])\n",
            "tensor([[-0.0370, -4.2475, -3.8169],\n",
            "        [-4.0457, -0.0330, -4.1993],\n",
            "        [-4.2150, -4.1447, -0.0311],\n",
            "        [-0.0252, -4.6070, -4.2077],\n",
            "        [-3.8959, -0.0215, -6.9592]])\n",
            "The\tdog\tate\tthe\tapple\n",
            "DET\tNN\tV\tDET\tNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augment Char Embedding"
      ],
      "metadata": {
        "id": "ZYSIxqX6YY6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_char = set([char for data in training_data for el in data[0] for char in el])\n",
        "char_to_idx = {char:idx for idx, char in enumerate(vocab_char)}"
      ],
      "metadata": {
        "id": "zbuisGYwPg7o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_PYXoJfTLzt",
        "outputId": "b41d0a6b-7102-4201-d106-02f5e6523b4d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d': 0, 'y': 1, 'r': 2, 'h': 3, 'a': 4, 'T': 5, 'e': 6, 'p': 7, 'v': 8, 'E': 9, 'l': 10, 'b': 11, 't': 12, 'k': 13, 'o': 14, 'g': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AugCharTagger(nn.Module):\n",
        "  def __init__(self, word_embed_dim, char_embed_dim, word_hidden_dim, char_hidden_dim,\n",
        "               word_vocab_size, char_vocab_size, tagset_size):\n",
        "    super(AugCharTagger, self).__init__()\n",
        "    self.word_embed = nn.Embedding(word_vocab_size, word_embed_dim)\n",
        "    self.char_embed = nn.Embedding(char_vocab_size, char_embed_dim)\n",
        "\n",
        "    self.char_lstm = nn.LSTM(char_embed_dim, char_hidden_dim)\n",
        "    self.word_lstm = nn.LSTM(word_embed_dim + char_hidden_dim, word_hidden_dim)\n",
        "\n",
        "    self.hidden2tag = nn.Linear(word_hidden_dim, tagset_size)\n",
        "    self.word_hidden = self.init_hidden(word_hidden_dim)\n",
        "    self.char_hidden = self.init_hidden(char_hidden_dim)\n",
        "\n",
        "  def init_hidden(self, size):\n",
        "    return (torch.zeros(1, 1, size), torch.zeros(1, 1, size))\n",
        "\n",
        "  def forward(self, word_sequence, char_sequence):\n",
        "    word_embeds = self.word_embed(word_sequence)\n",
        "\n",
        "    char_embeds = self.char_embed(char_sequence)\n",
        "    char_lstm_out, self.char_hidden = self.char_lstm(\n",
        "        char_embeds.view(len(char_sequence), 1, -1), self.char_hidden)\n",
        "\n",
        "    concat = torch.cat([word_embeds.view(1, 1, -1), char_lstm_out[-1].view(1, 1, -1)], dim=2)\n",
        "    word_lstm_out, self.word_hidden = self.word_lstm(concat, self.word_hidden)\n",
        "\n",
        "    tag_space = self.hidden2tag(word_lstm_out.view(1, -1))\n",
        "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "    return tag_scores"
      ],
      "metadata": {
        "id": "oRFGBOe_TPxj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_EMBED_DIM = 6\n",
        "WORD_HIDDEN_DIM = 6\n",
        "CHAR_EMBED_DIM = 3\n",
        "CHAR_HIDDEN_DIM = 3\n",
        "model = AugCharTagger(WORD_EMBED_DIM, CHAR_EMBED_DIM, WORD_HIDDEN_DIM, CHAR_HIDDEN_DIM,\n",
        "                      len(vocab), len(vocab_char), len(tag_to_idx))\n",
        "loss_fun = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "with torch.no_grad():\n",
        "  tag_scores = []\n",
        "  for word in training_data[0][0]:\n",
        "    word_sequence = prepare_sequence([word], word_to_idx)\n",
        "    char_sequence = prepare_sequence(word, char_to_idx)\n",
        "    tag_score = model(word_sequence, char_sequence)\n",
        "    tag_scores.append(tag_score)\n",
        "  print_beauti_res(training_data[0][0], tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgIS3LAJUjfF",
        "outputId": "0ddceb46-d788-4681-c22b-2317747d8e28"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\tdog\tate\tthe\tapple\n",
            "V\tV\tV\tNN\tNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(300):\n",
        "  for sentence, tags in training_data:\n",
        "    model.zero_grad()\n",
        "    model.word_hidden = model.init_hidden(WORD_HIDDEN_DIM)\n",
        "\n",
        "    for index, word in enumerate(sentence):\n",
        "      model.char_hidden = model.init_hidden(CHAR_HIDDEN_DIM)\n",
        "\n",
        "      word_sequence = prepare_sequence([word], word_to_idx)\n",
        "      char_sequence = prepare_sequence(word, char_to_idx)\n",
        "      targets = prepare_sequence([tags[index]], tag_to_idx)\n",
        "\n",
        "      tag_scores = model(word_sequence, char_sequence)\n",
        "      loss = loss_fn(tag_scores, targets)\n",
        "      loss.backward(retain_graph=True)\n",
        "      \n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "nHPGLIHvWGzu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  tag_scores = []\n",
        "  for word in training_data[0][0]:\n",
        "    word_sequence = prepare_sequence([word], word_to_idx)\n",
        "    char_sequence = prepare_sequence(word, char_to_idx)\n",
        "    tag_score = model(word_sequence, char_sequence)\n",
        "    tag_scores.append(tag_score)\n",
        "  print_beauti_res(training_data[0][0], tag_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR8zeEtnYRzr",
        "outputId": "66af7f1a-3566-40ef-e24a-54c15f98bb25"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The\tdog\tate\tthe\tapple\n",
            "DET\tNN\tV\tDET\tNN\n"
          ]
        }
      ]
    }
  ]
}